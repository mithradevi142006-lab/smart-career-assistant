# streamlit_app.py
import streamlit as st
from PIL import Image
import openai

# ---------- OpenAI API Key ----------
openai.api_key = "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"

# ---------- App Title ----------
st.set_page_config(page_title="NXT Wave Buildathon Prototype", layout="centered")
st.title("ðŸš€ NXT Wave Buildathon Prototype")
st.markdown("A simple prototype showing GPT, DALLÂ·E, and Whisper integration")

# ---------- Sidebar ----------
st.sidebar.header("Settings")
api_key_input = st.sidebar.text_input("Enter OpenAI API Key", type="password")
if api_key_input:
    openai.api_key = api_key_input

# ---------- Input Section ----------
st.subheader("Ask something to GPT")
user_input = st.text_input("Type your query here...", "")

# Centering the input box
st.markdown(
    """
    <style>
    div[data-baseweb="input"] > input {
        text-align: center;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ---------- GPT Response ----------
if st.button("Generate GPT Response"):
    if user_input.strip() != "":
        with st.spinner("Generating response..."):
            try:
                response = openai.ChatCompletion.create(
                    model="gpt-4",
                    messages=[{"role": "user", "content": user_input}],
                    temperature=0.7,
                )
                answer = response.choices[0].message['content']
                st.success("âœ… Response from GPT:")
                st.write(answer)
            except Exception as e:
                st.error(f"Error: {e}")
    else:
        st.warning("Please enter a query.")

# ---------- DALLÂ·E Image Generation ----------
st.subheader("Generate an Image with DALLÂ·E")
image_prompt = st.text_input("Enter image description...", "")
if st.button("Generate Image"):
    if image_prompt.strip() != "":
        with st.spinner("Generating image..."):
            try:
                img_response = openai.Image.create(
                    prompt=image_prompt,
                    n=1,
                    size="512x512"
                )
                img_url = img_response['data'][0]['url']
                image = Image.open(openai.util.url_to_image(img_url))
                st.image(image, caption="Generated by DALLÂ·E")
            except Exception as e:
                st.error(f"Error: {e}")
    else:
        st.warning("Please enter an image description.")

# ---------- Whisper Audio Transcription ----------
st.subheader("Transcribe Audio with Whisper")
uploaded_file = st.file_uploader("Upload audio file", type=["mp3", "wav", "m4a"])
if uploaded_file:
    with st.spinner("Transcribing audio..."):
        try:
            transcript = openai.Audio.transcriptions.create(
                model="whisper-1",
                file=uploaded_file
            )
            st.success("âœ… Transcription:")
            st.write(transcript.text)
        except Exception as e:
            st.error(f"Error: {e}")

