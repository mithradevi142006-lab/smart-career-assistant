# streamlit_app.py
import streamlit as st
from PIL import Image
import openai
from dotenv import load_dotenv
import os

# ---------- Load API key safely ----------
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
st.write("API Key loaded?",bool(openai.api_key))
# ---------- Page Config ----------
st.set_page_config(
    page_title="NXT Wave Buildathon Prototype",
    layout="wide"
)
st.title("üöÄ NXT Wave Buildathon Prototype")
if st.button("Test GPT"):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": "Hello GPT, are you working?"}]
        )
        st.write(response.choices[0].message["content"])
    except Exception as e:
        st.error(f"Error: {e}")
st.markdown("A polished prototype showing GPT, DALL¬∑E, and Whisper integration")

# ---------- Instructions ----------
st.markdown(
    """
    <div style="padding:15px; border-radius:10px; background-color:#e0f7fa; margin-bottom:20px;">
    <h4>üìå How to Use This Prototype:</h4>
    <ol>
        <li><b>Chat with GPT:</b> Type your query and click "Generate GPT Response".</li>
        <li><b>Generate Images:</b> Enter description and click "Generate Image".</li>
        <li><b>Transcribe Audio:</b> Upload an audio file to get transcription.</li>
    </ol>
    </div>
    """,
    unsafe_allow_html=True
)

# ---------- CSS ----------
st.markdown(
    """
    <style>
    .card {
        padding: 20px;
        border-radius: 15px;
        background-color: #f5f5f5;
        margin-bottom: 20px;
        box-shadow: 2px 2px 10px #ccc;
    }
    div[data-baseweb="input"] > input {
        text-align: center;
    }
    .stButton>button {
        width: 100%;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ---------- Columns Layout ----------
col1, col2, col3 = st.columns(3)

# ---------- GPT Chat ----------
with col1:
    st.subheader("üí¨ Chat with GPT")
    st.markdown('<div class="card">', unsafe_allow_html=True)
    gpt_input = st.text_input("Type your query...", key="gpt_input")
    if st.button("Generate GPT Response", key="gpt_btn"):
        if gpt_input.strip() != "":
            with st.spinner("Generating GPT response..."):
                try:
                    response = openai.ChatCompletion.create(
                        model="gpt-4",
                        messages=[{"role": "user", "content": gpt_input}],
                        temperature=0.7,
                    )
                    st.success("‚úÖ GPT Response:")
                    st.write(response.choices[0].message['content'])
                except Exception as e:
                    st.error(f"Error: {e}")
        else:
            st.warning("Please enter a query.")
    st.markdown('</div>', unsafe_allow_html=True)

# ---------- DALL¬∑E Image ----------
with col2:
    st.subheader("üñºÔ∏è Generate Image")
    st.markdown('<div class="card">', unsafe_allow_html=True)
    image_prompt = st.text_input("Describe the image...", key="img_input")
    if st.button("Generate Image", key="img_btn"):
        if image_prompt.strip() != "":
            with st.spinner("Generating image..."):
                try:
                    img_response = openai.Image.create(
                        prompt=image_prompt,
                        n=1,
                        size="512x512"
                    )
                    img_url = img_response['data'][0]['url']
                    image = Image.open(openai.util.url_to_image(img_url))
                    st.image(image, caption="Generated by DALL¬∑E")
                except Exception as e:
                    st.error(f"Error: {e}")
        else:
            st.warning("Please enter a description.")
    st.markdown('</div>', unsafe_allow_html=True)

# ---------- Whisper Audio ----------
with col3:
    st.subheader("üé§ Transcribe Audio")
    st.markdown('<div class="card">', unsafe_allow_html=True)
    uploaded_file = st.file_uploader("Upload audio file", type=["mp3", "wav", "m4a"], key="audio_uploader")
    if uploaded_file:
        with st.spinner("Transcribing audio..."):
            try:
                transcript = openai.Audio.transcriptions.create(
                    model="whisper-1",
                    file=uploaded_file
                )
                st.success("‚úÖ Transcription:")
                st.write(transcript.text)
            except Exception as e:
                st.error(f"Error: {e}")
    st.markdown('</div>', unsafe_allow_html=True)
